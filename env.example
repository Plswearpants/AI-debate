# AI Debate Platform - Environment Configuration
# Copy this file to .env and fill in your actual values

# ============================================================================
# REQUIRED: API Keys
# ============================================================================

# ────────────────────────────────────────────────────────────
# OPTION A: OpenRouter (Recommended - Simplest Setup)
# ────────────────────────────────────────────────────────────
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# Use OpenRouter for crowd voting (recommended)
USE_OPENROUTER_FOR_CROWD=true

# ────────────────────────────────────────────────────────────
# OPTION B: Direct API Keys (Advanced - Optional)
# ────────────────────────────────────────────────────────────
# Only needed if NOT using OpenRouter

# Google Gemini (for debators with research)
# Get from: https://aistudio.google.com/app/apikey
# GEMINI_API_KEY=your-gemini-key

# Anthropic Claude (for neutral judge)
# Get from: https://console.anthropic.com/
# CLAUDE_API_KEY=your-claude-key

# Perplexity AI (for fact-checkers with web search)
# Get from: https://www.perplexity.ai/settings/api
# PERPLEXITY_API_KEY=your-perplexity-key

# Lambda GPU (for crowd voting batch inference)
# LAMBDA_GPU_ENDPOINT=http://your-lambda-ip:8000
# LAMBDA_GPU_API_KEY=your-lambda-key

# ============================================================================
# MODEL CONFIGURATION (Optional - Defaults to free tier)
# ============================================================================

# Debators (Gemini with research capabilities)
GEMINI_MODEL=google/gemini-2.0-flash-exp:free

# Judge (Claude for neutral analysis)
CLAUDE_MODEL=anthropic/claude-3.5-sonnet:free

# Fact-checkers (Perplexity for web search)
# Free model (synthetic citations):
PERPLEXITY_MODEL=perplexity/llama-3.1-sonar-small-128k-online
# Paid model (real citations): perplexity/llama-3.1-sonar-large-128k-online

# Crowd (Llama for batch voting)
CROWD_MODEL=meta-llama/llama-3.3-70b-instruct:free

# ============================================================================
# DEBATE SETTINGS (Optional - Defaults shown)
# ============================================================================

# Number of rebuttal rounds (default: 2)
# More rounds = longer debate, higher cost
NUM_DEBATE_ROUNDS=2

# Number of voters (default: 10, max: 100)
# More voters = more diverse opinions, longer runtime
NUM_VOTERS=10

# ============================================================================
# COST CONTROLS (Optional - Defaults shown)
# ============================================================================

# Maximum cost per debate in USD (default: 5.00)
DEBATE_BUDGET_USD=5.00

# Cost budget preset: conservative, balanced, or premium
# - conservative: ~$2/debate, minimal research
# - balanced: ~$5/debate, standard research (default)
# - premium: ~$15/debate, exhaustive research
COST_BUDGET_PRESET=balanced

# Per-research cost limit in USD (default: 0.20)
MAX_COST_PER_RESEARCH=0.20

# ============================================================================
# ADVANCED SETTINGS (Optional - For experts)
# ============================================================================

# Enable/disable deep research phase (default: true)
DEEP_RESEARCH_ENABLED=true

# Temperature controls creativity (0.0-1.0)
# Lower = more deterministic, Higher = more creative
GEMINI_TEMPERATURE=0.7
CLAUDE_TEMPERATURE=0.3
PERPLEXITY_TEMPERATURE=0.2
CROWD_TEMPERATURE=0.8

# Max tokens per agent response
MAX_TOKENS_DEBATOR=4096
MAX_TOKENS_JUDGE=2048
MAX_TOKENS_FACTCHECKER=1024
MAX_TOKENS_CROWD=100

# Resource multiplier threshold (0.0-1.0)
# When audience bias exceeds this, losing side gets resource boost
RESOURCE_MULTIPLIER_THRESHOLD=0.6

# Maximum research calls per debate
MAX_DEEP_RESEARCH_CALLS=4

# Research limits
MAX_GROUNDING_QUERIES=10
MAX_CONTEXT_TOKENS=150000
MAX_OUTPUT_TOKENS=8000
MAX_RESEARCH_TIME=300

# Enable/disable components (default: all true)
ENABLE_FACTCHECKING=true
ENABLE_JUDGING=true
ENABLE_CROWD_VOTING=true

# Retry settings
MAX_RETRIES_PER_TURN=3
RETRY_DELAY_SECONDS=2

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ============================================================================
# COST ESTIMATES (for reference only)
# ============================================================================

# Free Tier Setup (all free models as configured above):
#   Cost: $0.00
#   Limitations: Synthetic citations, rate limits
#   Use case: Development, testing
#   Expected behavior: Citations will be Google Scholar links

# Budget Tier Setup (Perplexity paid for research, free for others):
#   Cost: ~$0.50-1.00 per debate
#   Config: PERPLEXITY_MODEL=perplexity/llama-3.1-sonar-large-128k-online
#   Benefits: Real citations with URLs, better research quality
#   Use case: Production debates

# Premium Tier Setup (paid models for all agents):
#   Cost: ~$2.00-5.00 per debate
#   Config: Use paid tier models for all agents
#   Benefits: Best quality, no rate limits, fastest responses
#   Use case: High-stakes analysis, important decisions

# ============================================================================
# DOCUMENTATION
# ============================================================================

# Setup Guide: DEPLOYMENT_GUIDE.md
# Citation Info: CITATION_QUALITY.md
# Architecture: ARCHITECTURE.md
# Cost Controls: COST_CONTROLS.md
# Troubleshooting: RAW_DATA_LOGGING.md
# Recent Changes: CHANGELOG.md
